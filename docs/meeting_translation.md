Noi in generale qualche prova l'abbiamo fatta ulteriormente. Ora, dato che io non ho accesso al computer perché sono in viaggio, semmai Riccardo mi dà la mano con la condivisione. In generale le prove che ho fatto io sono utilizzando una patch normale col body, su quell'API lì. Il risultato è che la risposta è corretta, fondamentalmente perché restituisce 204 no content, quindi essendo una patch potrebbe andare pure bene, però mi diceva Ugo, che è appena entrato, che non succede niente a livello di salvataggio dati. Quindi è come se comunque non accettasse, non accettasse questo metodo. Un'altra cosa che effettivamente ci chiedevamo è che noi in questo modo, anche utilizzando questa modalità, seppure troviamo qualcosa di sbagliato nella mia configurazione, comunque noi dovremmo fare in modo, utilizzando questa senza utilizzare il patch, dovremmo comunque fare in modo che siano delle chiamate reiterate, quindi in teoria giù lo chiamiamo, dovrebbe per ogni numero d'ordine fare una chiamata diversa, oppure, come dicevi tu, dovremmo noi sviluppare qualcosa in mezzo che faccia da collettore, quindi giù lo fra virgolette spara tutti gli ID degli ordini e tutti i campi che devono essere modificati per ogni ID, poi il cap di turno oppure il servizio, o data di turno su S4, fanno dei ragionamenti in modo che a queste API possa piacere. Sì, Ugo, ti ho visto. Dico l'ultima cosa. Altra alternativa è se esiste un'altra API che ci può aiutare in questo senso. Questa era un po' l'introduzione e l'attuale stato. Pronti alla discussione. Più o meno. Allora, sul fatto che, appunto, eventualmente anche se usassimo questa, cioè se riusciamo a far funzionare questa patch, lavora su un singolo dato, corretto, infatti è così, bisognerebbe capire all'interno dell'applicazione standard dove voi avete recuperato questo, questo servizio data, qual è il funzionamento quando viene richiesto l'aggiornamento massivo. Cioè se usa un'altra API o se usa questa richiamata in modo diverso. Scusa, Mattia, sono Ugo. Facciamo un passo indietro. Noi siamo partiti da un'applicazione standard di modifica massiva che consentiva la modifica dei tre dati che ci sono richiesti. Sì, però è che la manager says order del retailer. Sì, abbiamo messo sotto trace, abbiamo visto che chiama, questa API qua, e abbiamo analizzato la chiamata che viene fatta, che è la batch famosa che Giu Studio non è capace di replicare, di fare. Ergo, questa API... Aspetta, aspetta, nella batch però, quella che almeno mi ha condiviso Dario in quella chat, c'era una modifica sola. No. No, ho spiegato a Dario, non so se ti è arrivata la... Come dire, la prima chiamata è su un ordine fantoccio. Il... Il set di ordini che lui sente di dover modificare è quello determinato dalla get successiva. Cioè, funziona così. Tu, i parametri di filtro per selezionare gli ordini di venta da modificare, li esprimi nella get. Dopodiché, all'interno del batch, all'interno del change set del batch, gli dici, guarda, voglio modificare il campo A con questo valore, il campo B con quest'altro valore, il campo C con quest'altro valore. Questo è il comportamento di questa API, che fa solo modifiche massive, in questo modo. È schedule on job, tra l'altro. Non è che dà un esito sincrono. Dice, ho schedulato un job. Se noi vogliamo andare a fare una modifica puntuale, vogliamo andare a prendere un'altra API, ce ne sono, c'è sicuramente, però, siccome, come dire, il requirement di partenza è una modifica massiva, a quel punto vale quello che diceva Dario poco fa. Cioè, ci vuole un meccanismo, lato studio, o lato BTP, o lato non lo so, che cicla sulla base degli ordini estratti prima, grazie al prompt che ho chiesto, o tirami fuori tutti gli ordini di vendita fatti così, così e colà, e questa si è capace di ciclare e chiamare l'API per la modifica puntuale di un singolo ordine di vendita. Per conto mio, sperare che un'API che è fatta per le modifiche massive possa funzionare in patch diretto con una modifica puntuale, sono molto poco propenso a pensare che possa funzionare. Non so se sono riuscito a spiegarmi. Sì, sì, no, no, questo è chiaro. Però allora facciamo un passo indietro vero, andiamo a vedere un esempio di chiamata funzionante dell'API standard. Quella che abbiamo mandato. È quella che abbiamo mandato che funziona da Postman, noi l'abbiamo fatta da Postman. Se me la fate vedere così la proviamo, perché io non la posso testare, non ho un sistema retail dove provarlo, quindi non riesco neanche a riprodurre il... lo scenario. Devo collegarmi? Io non sono collegato al sistema, sedite, dovete aspettare cinque minuti che mi colleghi, tiri fuori e ha proposto eccetera, eccetera. Conviene. È un momento di pazienza. Io avevo un altro dubbio. Ok. Mattia, nel caso in cui, diciamo giusto per occupare il tempo, nel caso in cui poi dovessimo utilizzare un qualcosa del genere, quindi mettere un servizio e mezzo che faccia da dispatcher con le varie logiche. Ma Giul, perché questo è uno dei dubbi che mi è venuto, in che modo si comporterebbe, nel momento in cui in teoria... anzi la dico meglio, come potremmo fare per far capire a Giul, in teoria che in quel momento l'API che viene richiamata da una risposta con 200, ma in realtà tutto il flusso ha acceso un job, quindi non c'è un ok è andato tutto bene, io immagino che richiamando un API, Giul riceva il 200 e dica ok a posto, quello che volevi fare è stato fatto. In questo caso, che tu sappia c'è un modo per veicolare invece la risposta dicendo vedi che è partito un job, per controllare se tutto è andato bene, vai a sistema e controlla i dati che hai salvato. Oppure, non lo so, mi era venuto questo dubbio su qualcosa di asincrono, cioè come potrebbe essere veicolato secondo te. La risposta, perché diciamo che nelle istruzioni uno potrebbe dire anche, ma anche in cui ricevi il 200 l'API, non so se è una cosa possibile, però in cui ricevi il 200 l'API all'utente rispondimi sempre che è partito un job, invece che ok è tutto a posto. In realtà dipende anche da come costruite poi, cioè da cosa ritorna, perché potenzialmente potreste che ne so ritornare l'ID del job, cioè poi dipende effettivamente dal comportamento che andate ad implementare, nel senso che poi come avete visto in realtà all'interno di studio potete decidere di fargli generare una una response in base al, al payload, oppure anche di crearla in modo in modo manuale. Quella cosa lì del gestire, se riceve 200, non saprei se è un qualcosa di così robusto, diciamo. Perché effettivamente diciamo qualsiasi cosa c'è nel mezzo, quindi che sia un capo, che sia, qualcosa di uno data sviluppato su S4, in quel momento come dici tu, può restituire l'ID del job sempre 200 è la risposta. Cioè non so se c'è un modo per dire sì la chiamata è andata bene, ma sappi che è partito un job, non è stata salvata l'informazione come tu mi hai chiesto, è partito un job che farà questa cosa. E questo era uno dei, dei dubbi che mi, che mi veniva in mente al momento in cui Ugo mi disse che il tutto non era, non era asincrono. Era asincrono. Stavo, stavo un attimo pensando a cosa potrebbe essere meglio fare. Lì no, lì no, è aperta, è aperta la discussione. Io non so se tramite, le istruzioni iniziali, diciamolo, si può forzare a dire anche se ti arriva 200, rispondi sempre con questo ID del job, vai a controllare lo stato. Cioè a quel punto però servirebbe proprio una forzatura di prompt abbastanza, di istruzione abbastanza importante. Cioè rispondimi, nel caso in cui ricevi 200 rispondimi sempre in questo modo. Non so neanche se è corretta una cosa del genere. Però veramente se tiフ Adult tantomeno si compra anche il brace che進 Aha quando c'erano altre opp preliminary iz- . Quindi magari allora dovevo even con una partner ne erlf benessi e cazze usare l' attracting utile, cioè se la chiedevano, le di gy umi non le lasciavano costi,APPALLA L' importante logico delle forze per rispondere all' incorrecto. Quindi dama vi loops astrisíprhigh ma stubby che comporta i risultati del vorrei esserci condivido lo schermo allora ditemi quando vedete vediamo ok la chiamata incriminata è questa qui che poi è quella che è stata mandata condivisa via mail il meccanismo di fondo è il seguente la get che vedete che io sto evidenziando è quella che effettua il filtro sugli ordini di vendita da modificare quindi il filtro che noi abbiamo immaginato è i materiali che iniziano per una certa stringa dal punto di vista funzionale significa andare a modificare tutte le righe e ordini di vendita che hanno uno stesso materiale generico quindi cominciano per una certa sequenza di caratteri un certo plant il plant 142A una certa data creazione del documento questo a me era funzionale per andare a delimitare opportunamente il filtro delle righe e ordini da modificare e l'organizzazione commerciale uguale a 142 replicando questa stessa selezione con un report qualsiasi su SAP la lista ordini di vendita quindi il materiale che inizia per quella stringa data di vendita creazione 13 di gennaio 26 organizzazione commerciale 142 ottengo tre righe di tre ordini di vendita differenti quale dato viene modificato da questa chiamata? vengono modificati i requirement segment che sto evidenziando con il valore ppcomfr il plant che viene modificato da 142A a 140A e la storage location che viene modificata da AFS a ROD il resto sono dati che SAP usa in maniera non trasparente non sappiamo non ho la più pari idea di cosa se ne faccia ma che abbiamo come dire desunto ripeto dalla traccia, dal trace che abbiamo acceso eseguendo l'applicazione standard da FIORI quindi se io adesso eseguo questo signore qua la risposta è accepted e il risultato è sperabilmente che l'ordine abbia il segmento che fa bisogno ppcomfr alla divisione 140A e al magazzino ROD cioè le tre informazioni che abbiamo detto di modificare e che sono tracciate anche dalla lista delle modifiche allora qua siamo per data vediamo che in fondo qua ci sono queste modifiche fatte il 28 dell'1 alle 17 17 e 12 ossia da me due secondi fa che hanno modificato che hanno modificato qua sono quelle importanti 28 dell'1 alle 17 e 17 il plant da 142A valore precedente a 140A valore attuale il segmento fa bisogno da ppcom99 a ppcomfr e il magazzino da AFS a ROD per fare questo lui ha schedulato un job che ha i suoi esiti eccetera eccetera però questo è come dire il film dal punto di vista funzionale e questa è la chiamata postman che ha ottenuto tutto questo quindi la cosa importante da dire è che quello che voi vedete qua questo merge qua con questo numero questo numero ordine di vendita qua non ha nulla a che vedere con gli ordini di vendita che vengono modificati gli ordini che vengono modificati sono in questo caso ok diciamo che questa cosa neanche a me era chiara quindi il 25, 26, 27 spero di essere spiegato no no in quella patch lì non ci sono cioè il body sono i campi da modificare comunque ritorno come dire a testa bassa a costo di sembrare uno zucone questa API qua lavora così lavora col badge ci sono alternative per conto mio si si adesso mi è chiaro il il funzionamento allora in questo momento c'è il il il limite all'interno che non è di Joule Studio in realtà delle action quindi anche in process automation se volete creare un action project non è supportato l'utilizzo della chiamata batch la skill standard quella che abbiamo visto che non copre il tutto funziona perché non è fatta con Joule Studio è fatta con la parte pro code che garantisce un po' più di libertà in questo caso in questo senso quindi dal punto di vista del diciamo della possibilità percorrere è un'idea che appunto era venuta a fronte della discussione con Dario in chat era quello appunto di mettere in mezzo un qualche tipo di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di di da modificare che la lista dei campi da modificare giusto esatto praticamente io la immagino come un array di D più un JSON di più un oggetto di diciamo di campi da modificare se la dovessi immaginare ora cioè l'obiettivo potrebbe essere quella che dall'action all'odata al cap di turno che sia arrivi un JSON o dentro un array di D e un set di dati da modificare l'ho immaginato così più o meno dall'inizio però se posso Dario questo mi apre molti dubbi cioè da un lato vabbè ci stiamo dicendo bisogna fare custom e vabbè questo vuol dire forse lo sapevamo dall'inizio in seconda battuta vuol dire se gli passi 10 ordini di vendita può anche stare in piedi un impianto del genere se gli passi 1500 vuol dire che è un servizio che sta lì aperto e aspetta una valanga di tempo potenzialmente quindi non è dal punto di vista infrastrutturale diciamo così una cosa particolarmente consigliabile aspetta nel momento in cui noi il comunque l'approccio al job deve rimanere per forza e quindi deve essere asincrono e quindi deve esserci un meccanismo che intercetta il numero del job staccato e un altro servizio custom che vada a recuperare gli esiti del job questo beccia la parte 200 non ti torna un id job? no è come si potrebbe capire l'app standard ti dice ho fatto dopodiché ti dice vai nell'app con la lista dei job a vedere cosa è successo ah ok quindi fa un polling della get da qualche parte con ogni probabilità è un altro servizio? no non va con job id vai nel monitor dei job e trova esatto il servizio è dammi la lista dei job fatti dopodiché lui i job li battesa con un nome e tu puoi filtrare per nome però non è che vai non è che punti a quello specifico job che lui ha staccato con la chiamata al servizio precedente no mi è chiaro Ale io non so chi diciamo chi ha smanettato e questo comportamento però si può si può replicare cioè nel senso esatto riceve la risposta la risposta di Giù sarà job schedulato vai a vederli no ma se non ti torna un id nel momento in cui c'è concorrenza come fai? però questo è lo stesso lo avresti anche nell'app standard cioè stiamo dicendo è per capire perché se si vuole usare questo approccio dell'API usata dall'app standard l'app standard se la stanno usando due persone diverse hai lo stesso problema vengono schedulati due job e uno non può sapere qual è il suo quindi diciamo che il fatto che venga scatenato da Giù piuttosto che da un utente il problema del non sapere qual è il tuo job è è un invariante no? quindi possiamo dire che se se vogliamo in qualche modo rendere la cosa meno complessa si può fare in modo di gestire il tutto con un quello che è semplicemente un proxy quindi lo immagino come un CAP piuttosto che una cosa fatta in ABAP che prende la la chiamata fatta da Giù che non è una patch scusa che non è una batch e la rigira sul servizio standard quindi in modo che non dobbiate fare niente di custom lì dentro e anche il funzionamento della scrivazione del job con le sue regole le sue cose rimane tutto uguale e bisogna solo trovare il modo di passare correttamente i parametri ma questa get che in teoria fa l'applicazione a uso non lo so se è polling o se se la richiesta dell'utente su qualche refresh non lo so questa qui è già gestita da Giul che noi sappiamo in qualche modo cioè è una di quelle get standard se tu chiedi a Giul dammi tutti gli ordini che sono in questo ti restituisce ti naviga verso la pagina oppure te li restituisce a video o qualcosa del genere stai dicendo se è una skill standard sì sì la domanda è questa get che in teoria noi che l'applicazione fa per diciamo per far vedere all'utente se se l'operazione massiva è andata bene o non è andata bene rientra già fra le operazioni standard di Giul o no o dovrebbe essere un'ulteriore skill da fare stai dicendo quindi la get per recuperare i job ho capito bene sì questo è da verificare non lo so c'è un'altra applicazione che lo fanno quindi lo possiamo verificare però non credo almeno tra quelle tra le skill di Giul nei processi sales non mi pare di averla vista no però la posso verificare in generale quindi le skills a questo punto diventerebbero due se ci troviamo tutti perché poi oltre a quella che deve che deve interrogare il proxy dobbiamo aggiungere pure quella che in teoria va a recuperarsi i job sì sì corretto immagino di sì l'alternativa cioè l'alternativa non può essere che forse questa sì che è una skill già già presente cioè chiedere a skill un'estrazione con la stessa selezione degli ordini con cui l'utente prima gli ha chiesto di modificare per ottenere per vedere da un report quindi da una lista di ordini se quei dati lì sono stati aggiornati è un po' una forzatura però adesso lo sto anche immaginando perché noi stiamo in un'altra elaborando un POC quindi adesso non è che dobbiamo cioè in questa fase qua secondo me è importante che mostriamo che riusciamo ad aggiornarle poi la capacità di monitorare non è un aspetto secondario ma se in questa fase comunque ci fosse una skill presa la quale cioè l'utente reinterroga Giulia per chiedere l'estrazione di quella stessa selezione e poi l'altra che è un'altra che è un'altra che è un'altra che è un'altra che è un'altra che è diciamo gli aveva fatto modificare per aver per verificare no lui stesso se il contenuto è stato aggiornato col nuovo plan storage location e requirement segment potrebbe essere un work around rispetto andare a recuperare esattamente l'id del job e costruire qualcosa di custom che vada a interrogare lo stato di quel job il log di quel job e non so se visualizzare se si accontentano tipo che tu sai che l'ordine x y z prima era diciamo ricade all'interno del set di quelli modificati e quindi dopo che hai lanciato la modifica massiva dici guarda ad esempio io prendo quest'ordine qua che era dentro nell'insieme quindi chiedo a Jul mostrami l'ordine x y z e gli si fa vedere che i dati oggetto di modificazione massiva effettivamente sono stati aggiornati dico come quello in teoria appunto è già coperto da cioè io in questa fase qua cioè rimanendo nel perimetro del POS mi fermerei qua cioè non starei a immaginare anche cosa e a fare soprattutto cosa cioè come andare a recuperare l'id di un job che ha lanciato per verificarne lo stato alla fine non stiamo rilasciando un POS stiamo rilasciando una soluzione per anche un po' testare l'applicabilità lato business non è che quando la rilasceremo l'utente francamente sarà utilizzata da subito ci sarà ancora un po' di lavoro magari da fare per affinarlo anche perché ricordo che adesso noi stiamo gestendo un sotto insieme piccolo piacere delle diverse casistiche quindi ci sono un po' delle cose nel concetto di POS che non andiamo a sviluppare una cosa che sia finita al 100% Sì Alessandro sono d'accordo ma altrimenti non so quanto complesso però se Jules restituisse come in alcuni casi appunto fa il link dell'applicazione quindi la mass change e poi da lì comunque c'è la lista dei vari dei vari job è vero che non sono particolarmente parlanti però per esempio c'è appunto la data insomma di creazione c'è l'utente che ha creato il job e poi insomma da lì poi si può navigare e verificare appunto se Navighi direttamente l'applicazione a quel punto Esatto cioè ti faccio vedere non so se riesco a condividere però dovrebbe essere questo ho capito quello che fai riferimento non è quella l'applicazione quella non è capace di modificare tutti e tre i dati è quella specifica del mondo fashion ce l'ho sotto mano io se vuoi ah quella se mi passi sì perché è uno dei campi specifico del mondo fashion il requirements ah è la monitor è giusto è vero è vero è questa qui manage sense document fashion e se vuoi l'id è la f45 4646 ok grazie dovrei verificare se quella no però non dovrebbe comparire qua dentro il job da quella effettivamente non credo credo che torni a farvi vedere quando tu hai schedulato vedi tu hai qua ah eccole sì il job overview ti manda e questo qua è quello che ho fatto da postman poco fa eh è quello che ho fatto ho capito quindi non è che ti ti dà come dire una schermata di selezione di me o che ti fa ti fa puntare direttamente ti dice vai a vedere nella lista quando tu scheduli la modifica di mass lui ti chiede di dare un nome al job infatti se notate quello che io ho schedulato da postman lui è chiamato mass field update andata se io torno su postman qua da qualche parte c'era scritto eccolo qua mass field update andata quindi c'è modo di battezzarlo diciamo così dall'esterno il job però è un po' macchinoso però io non so però Alessandro mi rivolgo un po' a te cioè è vincente mostrare al cliente che ci tocca fare alla fine sviluppi la tua backup cioè allora ragazzi in questo caso diciamo forse come diceva Mattia la scelta migliore è farli sul BTP quindi vabbè è uguale cambia poco lo farei probabilmente anch'io lo farei più su BTP questo cap lo farei più sposterei un po' la complessità sul BTP poi per me l'obiettivo non è quello di dimostrare che riusciamo a fare tutto con senza dover sviluppare no? cioè l'obiettivo è quello così di di dimostrare quelle che sono le capability standard e comunque dimostrare che anche laddove lo standard non arriva in qualche modo si riescono a compensare quelle capability con un custom indipendentemente che venga fatto con Giustudio in una modalità no code no code oppure dovendoci mettere come un po' la prospettiva nella quale stiamo andando delle righe di codice cioè quindi l'obiettivo più che altro è quello di arrivare a dimostrare un'applicabilità e un'utilità lato business no? di queste di queste dell'utilizzo di giù anche un po' per sondare no? quello che è la reazione lato lato loro no? questo è un po' l'obiettivo del POS non è tanto quello di dimostrare che si riescono a fare senza dover mettere ulteriore ulteriore custom se non lo specifico questa condividiamo no? tutti insieme che questa è la strada migliore c'è bisogno di sviluppare qualche riga di codice la farei lo farei eh eh e presenterei quello che è lo stato dell'arte poi eh quello che è la realtà adesso preme più che altro capire adesso tenendo da parte un po' il tema del del monitor del cioè di come andare a monitorare l'esito no? volevo un attimino sicurarmi se condividiamo che per far funzionare questo scenario bisogna fare quello sviluppo quel mapping eh sul BTP per eh diciamo riconvertire un servil diciamo la la la chiamata di Giulio in un servizio eh nel servizio che si aspetta l'esforzo mi interessa che condividiamo un po' la soluzione tecnica no? in modo tale da essere poi autonomi nel poterla sviluppare e poi la presentiamo per quello che abbiamo fatto l'attimino per quello che conta Alessandro sì credo sia l'unica soluzione per Corribe tu Mattia ti trovi Mattia sì allora eh io in parallelo sto facendo anche delle verifiche che però appunto al momento non sono ancora completate anche perché appunto noi abbiamo questo evento a Lisbon dove un po' di gente è impegnata e con il product per da un lato capire se questa limitazione dentro nelle action sulle batch in qualche modo sarà superata in una delle prossime in una delle prossime release perché diventando un componente centrale del anche della parte AI questo tipo di vincolo è un po' un pochino fastidioso come ci siamo accorti vi siete accorti l'altra cosa l'alternativa eventualmente è anche quello di non usare giustudio ma creare la skill con la chiamiamola pro code che è la modalità con cui è stata creata la skill standard e che appunto come dicevo prima ha un po' più di flessibilità nel costruire chiamate quant'altro però questa è la terza è un po' come ultima spiaggia ecco perché noi abbiamo accesso alla parte pro code di jul o è un qualcosa legata solo al mondo sapere esatto devo verificare nel senso che dovrebbe essere già disponibile ma devo verificare che tipo di limitazioni ha perché poi la parte pro code alla fine si tratta di scrivere un un descrittore uno yaml che contiene la descrizione del comportamento di jul secondo una particolare sintassi la mia domanda è come si deploya qualcosa su jul si esatto quello che si può fare però appunto devo capire se è un qualcosa di già aperto al pubblico si o comunque formalizzato e in generale supportato quindi su questo lo appunto lo terrei come ultima spiaggia tornando al discorso del pro del proxio comunque diciamo di quello che gira la chiamata in realtà poi quel componente livi può diventare anche utile per eventualmente altri tipi di gestione di manipolazione dati per api o quant'altro nell'interazione con jul cioè può diventare in qualche modo un un componente che vi facilita nel caso in cui ci siano altri casi simili o comunque in generale abbiate la necessità di semplificare le le chiamate verso verso esporo sistemi esterni il in questo caso appunto avreste già un componente pronto e deployato che andrebbe solo solo esteso giusto anche per provare a giustificare il lo sviluppo di un di un qualcosa che si mette in mezzo però su questo appunto mi riservo ancora appunto di se mi date la giornata di stasera e domani per verificare meglio soprattutto magari sollecito il prodotto anche per capire il lato supporto alla batch perché magari è un qualcosa di appunto che sarà disponibile tra non molto e quindi magari può avere senso non dico aspettare però eh mettersi nelle condizioni per cui magari si fa un workaround che però poi non servirà più tra poco ok ok per me è chiaro quindi magari vabbè il workaround però non potrà non è diverso da quello che ci siamo detti comunque sì sì è quello è quello è un ok come si dice è un gioco si ma per magari si diciamo che aspettare domani non credo cambi molto quindi nel momento in cui Mattia ci dice al momento non non c'è nulla di lasciato e non lo sarà per il prossimo mese due mesi tre mesi noi noi possiamo possiamo partire con questa diciamo con questo sviluppo però io immagino che se Mattia domani arrivi e per qualche coincidenza strana strana eh per il rilascio della batch nelle action è al 5 febbraio credo che a quel punto abbia senso è chiaro è chiaro dato che Mattia comunque diciamo comunque si è riservato tra virgolette oggi e domani aspetterei solo domani la risposta vi aggiorno cerco di aggiornarvi appena ho qualsiasi tipo di feedback dal prodotto va bene ok io vi ringrazio della disponibilità credo sia stato molto utile alla prossima grazie a voi buona serata ciao buona serata ciao ciao